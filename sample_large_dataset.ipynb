{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 - Preprocessing du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"\\\\data\"\n",
    "output_path = path + \"\\\\outputs\"\n",
    "fig_path = path + \"\\\\figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation PEP8\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres graphiques\n",
    "%matplotlib inline\n",
    "rc = {\n",
    "    'font.size': 14,\n",
    "    'font.family': 'Arial',\n",
    "    'axes.labelsize': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'figure.max_open_warning': 30}\n",
    "\n",
    "sns.set(font='Arial', rc=rc)\n",
    "sns.set_style(\n",
    "    \"whitegrid\", {\n",
    "        'axes.edgecolor': 'k',\n",
    "        'axes.linewidth': 1,\n",
    "        'axes.grid': True,\n",
    "        'xtick.major.width': 1,\n",
    "        'ytick.major.width': 1\n",
    "        })\n",
    "sns.set_context(\n",
    "    \"notebook\",\n",
    "    font_scale=1.1,\n",
    "    rc={\"lines.linewidth\": 1.5})\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des données\n",
    "filename = \"export_sans_dewey.dsv\"\n",
    "with open(os.path.join(data_path, filename), 'r', newline='', encoding=\"utf-8\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter='\\t',)\n",
    "    data = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimension\n",
    "nb_notice = len(data)\n",
    "print(f\"There are {nb_notice} in this file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of column\n",
    "len_col = []\n",
    "for row in data:\n",
    "    len_col.append(len(row))\n",
    "max_number_col = max(len_col)\n",
    "print(f\"There are till {max_number_col} in this file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution\n",
    "sns.histplot(len_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and removing badly formatted notices\n",
    "official_nb_col = 5\n",
    "bad_formated_notices = [x for x in len_col if x != official_nb_col]\n",
    "print(f\"There are {len(bad_formated_notices)} badly formatted notices\")\n",
    "\n",
    "ids_to_keep = [True if x == official_nb_col else False for x in len_col]\n",
    "print(f\"There are {sum(ids_to_keep)} well formatted rows\")\n",
    "\n",
    "data = [row for row, boo in zip(data, ids_to_keep) if boo]\n",
    "print(f\"Working dataset has {len(data)-1} notices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du fichier de données à vérifier\n",
    "data_to_check = [row for row, boo in zip(data, ids_to_keep) if not boo]\n",
    "print(f\"Need to check {len(data_to_check)} notices extractions\")\n",
    "\n",
    "data_to_check = pd.DataFrame(data_to_check)\n",
    "print(data_to_check.shape)\n",
    "data_to_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des données à vérifier\n",
    "data_to_check.to_csv(\n",
    "    os.path.join(data_path, \"data_to_check_LargeExtraction.csv\"),\n",
    "    index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification du format des données\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "print(f\"le Fichier de données contient {df.shape[0]} lignes et  {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'une colonne description (Titre + resumé)\n",
    "df.loc[:, \"DESCR\"] = df.loc[:, 'TITRE'] + ' ' + df.loc[:, 'RESUME']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get RAMEAU labels (vedettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre à plat TOUS les mots clé\n",
    "pattern=re.compile(r\"[\\w;^\\s]| -- \")\n",
    "df[\"rameau_list_unstack\"] = df[\"RAMEAU\"].apply(lambda x: re.split(r';\\s*(?![^()]*\\))| -- ', x))\n",
    "df.loc[1:20, [\"RAMEAU\",\"rameau_list_unstack\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = flatten(df['rameau_list_unstack'])\n",
    "print(f\"There are {len(set(keywords))} different RAMEAU labels (Vedettes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des vedettes\n",
    "print(Counter(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=1000, height=500, background_color='white').generate_from_frequencies(Counter(keywords))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retirer les notices avec les mits clés \"ouvrages pour la jeunesse\" et \"romans pour la jeunesse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_strings(df, col, string):\n",
    "    res = []\n",
    "    res = df[col].apply(lambda x: string in x)\n",
    "    print(f\"Nbre de notices contenant le concept {string} : {sum(res)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check notices\n",
    "string = \"Ouvrages pour la jeunesse\"\n",
    "col = \"rameau_list_unstack\"\n",
    "is_string = check_strings(df, col, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check notices\n",
    "string = \"Roman pour la jeunesse\"\n",
    "col = \"rameau_list_unstack\"\n",
    "is_string2 = check_strings(df, col, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction du jeu de données\n",
    "df_reduced = df[(is_string+is_string2) == 0]\n",
    "print(df_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "keywords2 = flatten(df_reduced['rameau_list_unstack'])\n",
    "wordcloud2 = WordCloud(\n",
    "    width=1000, height=500, background_color='white'\n",
    "    ).generate_from_frequencies(Counter(keywords2))\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(wordcloud2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering avant échantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echantillonnage\n",
    "nsample = 15000\n",
    "df_sample = df_reduced.sample(n=nsample).reset_index()\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected index\n",
    "selected_index = df_sample.index\n",
    "selected_index\n",
    "selected_ppn = df_sample[\"PPN\"]\n",
    "selected_ppn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export selected PPN\n",
    "pd.DataFrame(selected_ppn).to_csv(os.path.join(data_path, \"ppn_echantillon_150notices.csv\"), index=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des titres et résumé des notices\n",
    "df.loc[selected_index, [\"PPN\", \"TITRE\", \"RESUME\", \"RAMEAU\"]].to_csv(os.path.join(data_path, \"echantillon_150notices.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des mots clés\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(df_sample[\"rameau_list_unstack\"])\n",
    "classes = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check encoding\n",
    "labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inverse transformation\n",
    "nlab = 5\n",
    "labels_true = df_sample.loc[:5, \"rameau_list_unstack\"]\n",
    "print(f\"True {nlab} first labels : {labels_true}\")\n",
    "print(f\"Recoded {nlab} first labels : {mlb.inverse_transform(labels_encoded[:nlab])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classes\n",
    "nbr = 50\n",
    "print(f\"{classes[:nbr]} premiers mots clés (ordre alphabetique)\")\n",
    "print(f\"{classes[-nbr:]} derniers mots clés (ordre alphabetique)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering based on Kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different clusters\n",
    "sil = []\n",
    "davis_bouldin = []\n",
    "sum_of_squared_distances = []\n",
    "param_range = range(3, 20)\n",
    "for k in param_range:\n",
    "    print(f\"Clustering with {k} groups\")\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(labels_encoded)\n",
    "    clusters = kmeans.labels_\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "    silh = silhouette_score(\n",
    "        labels_encoded, clusters, metric=\"euclidean\", sample_size=10000, random_state=200\n",
    "        )\n",
    "    dav = davies_bouldin_score(labels_encoded, clusters)\n",
    "    sil.append(silh)\n",
    "    davis_bouldin.append(dav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal values accordin to silhouette and Davis-Bouldin scores\n",
    "opt_val_sil = param_range[sil.index(max(sil))]\n",
    "opt_val_db = param_range[davis_bouldin.index(min(davis_bouldin))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_val_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_val_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    sil, davis_bouldin, param_name, param_range, silhouette_color=\"red\", db_color=\"blue\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the silhouette score and davies_bouldin score for a range of cluster number.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        - sil (list): list of silhouette scores for all values of hyper-parameter range\n",
    "        - davis_bouldin (list): list of davies-bouldin scores along hyper-parameter range\n",
    "        - param_name (str): name of the hyper-parameter to be fined-tuned\n",
    "        - param_range (list) : range of possible values for hyper-parameter tuning\n",
    "        - silhouette_color (str): color for the silhouette score (defaut: 'red')\n",
    "        - db_color (str): color for the silhouette score (defaut: 'blue')\n",
    "\n",
    "    Returns :\n",
    "    ---------\n",
    "        - Evolution of silhouette and Davies-bouldin scores along hyper-parameter range\n",
    "    \"\"\"\n",
    "\n",
    "    # plot\n",
    "    _, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(param_name)\n",
    "    ax1.set_ylabel(\"Silhouette_score\", color=silhouette_color)\n",
    "    ax1.plot(param_range, sil, color=silhouette_color)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=silhouette_color)\n",
    "\n",
    "    # Adding Twin Axes\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Davies_bouldin\", color=db_color)\n",
    "    ax2.plot(param_range, davis_bouldin, color=db_color)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=db_color)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(sil, davis_bouldin, param_name=\"k\", param_range=param_range, silhouette_color=\"red\", db_color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inertia\n",
    "plt.plot(param_range, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('sum_of_squared_distances')\n",
    "plt.title('elbow method for optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best clustering\n",
    "k = 100\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph des silhouettes\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "print(\"Graph des Silhouettes\\n\")\n",
    "silhouette_vis = SilhouetteVisualizer(kmeans)\n",
    "silhouette_vis.fit(labels_encoded)\n",
    "silhouette_vis.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters\n",
    "# Fit visualisation pipeline\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(init=\"pca\").fit_transform(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TSNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "axe = plt.axes()\n",
    "clusters = kmeans.labels_\n",
    "num_classes = k\n",
    "palette = np.array(sns.color_palette(\"tab10\", num_classes))\n",
    "axe.scatter(x=tsne[:, 0], y=tsne[:, 1], c=palette[clusters.astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample[\"cluster\"] = clusters\n",
    "stratified_sampling = df_sample.sample(n=100, weights=clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_sampling[\"cluster\"].astype(\"object\").describe(include=\"all\")\n",
    "stratified_sampling[\"cluster\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected index\n",
    "selected_index = stratified_sampling.index\n",
    "selected_index\n",
    "selected_ppn = stratified_sampling[\"PPN\"]\n",
    "selected_ppn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export selected PPN\n",
    "pd.DataFrame(selected_ppn).to_csv(os.path.join(data_path, \"ppn_echantillon_100notices_stratified_on_50_clusters.csv\"), index=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abes_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "79d7ff32004ac4c5bc1812f118fca289ef6cc0cea24529fb05e42e57e2fccd5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
