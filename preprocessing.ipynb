{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 - Exploration des données (y compris préprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from utils_text_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autorisation pour la visualisation par pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres graphiques\n",
    "%matplotlib inline\n",
    "rc = {\n",
    "    'font.size': 14,\n",
    "    'font.family': 'Arial',\n",
    "    'axes.labelsize': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'figure.max_open_warning': 30}\n",
    "\n",
    "sns.set(font='Arial', rc=rc)\n",
    "sns.set_style(\n",
    "    \"whitegrid\", {\n",
    "        'axes.edgecolor': 'k',\n",
    "        'axes.linewidth': 1,\n",
    "        'axes.grid': True,\n",
    "        'xtick.major.width': 1,\n",
    "        'ytick.major.width': 1\n",
    "        })\n",
    "sns.set_context(\n",
    "    \"notebook\",\n",
    "    font_scale=1.1,\n",
    "    rc={\"lines.linewidth\": 1.5})\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "dpi = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des données\n",
    "df = pd.read_csv(os.path.join(data_path, \"working_data.csv\"), index_col=0)\n",
    "print(f\"le Fichier de données contient {df.shape[0]} lignes et  {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des mots-clé RAMEAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:10, \"RAMEAU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des indices contenant \" -- \" dans la colonne RAMEAU => i.e chaines d'indexation\n",
    "df[\"test_tiret\"] = df[\"RAMEAU\"].apply(lambda x: True if re.search(' -- ', x) else False)\n",
    "df.loc[df[\"test_tiret\"]==True, [\"PPN\", \"RAMEAU\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 39141 notices avec des chaines d'indexation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des chaines d'indexation\n",
    "df[\"rameau_list\"] = df[\"RAMEAU\"].apply(lambda x: x.split(r'\\w;\\w'))\n",
    "print(df.loc[1:10, \"rameau_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rameau_list = df[\"rameau_list\"].tolist()\n",
    "type(rameau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de chaines d'indexation différentes\n",
    "from itertools import chain\n",
    "rameau_lists = df[\"rameau_list\"].tolist()\n",
    "rameau_list = list(chain(*rameau_lists))\n",
    "print(f\"{len(rameau_list)} chaines d'indexation, dont {len(set(rameau_list))} uniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot_of_tags(\n",
    "    tags_list=rameau_list,\n",
    "    nb_of_tags=20,\n",
    "    xlabel=\"Nombre de references\",\n",
    "    ylabel=\"RAMEAU - Chaines d'indexation\",\n",
    "    figsave=os.path.join(fig_path, 'barplot_Rameau_chaines_index.png'),\n",
    "    figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre à plat TOUS les mots clé\n",
    "pattern=re.compile(r\"[\\w;^\\s]| -- \")\n",
    "df[\"rameau_list_unstack\"] = df[\"RAMEAU\"].apply(lambda x: re.split(r';\\s*(?![^()]*\\))| -- ', x))\n",
    "df.loc[1:10, \"rameau_list_unstack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(df.loc[1:10, 'rameau_list_unstack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = flatten(df['rameau_list_unstack'])\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "wordcloud = WordCloud(width = 1000, height = 500, background_color='white').generate_from_frequencies(Counter(keywords))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot_of_tags(\n",
    "    tags_list=keywords,\n",
    "    nb_of_tags=20,\n",
    "    xlabel=\"Nombre de references\",\n",
    "    ylabel=\"RAMEAU - Mots clés\",\n",
    "    figsave='figures/barplot_Rameau_keywords_unstack.png',\n",
    "    figsize=(8, 8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des domaines DDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot_of_tags(\n",
    "    tags_list=df[\"TEF_LABEL\"],\n",
    "    nb_of_tags=20,\n",
    "    xlabel=\"Nombre de references\",\n",
    "    ylabel=\"Libellés TEF\",\n",
    "    figsave='figures/barplot_libelles_TEF.png',\n",
    "    figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"TEF_LABEL\"] == \"Sciences sociales, sociologie, anthropologie\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"TEF_LABEL\"] == \"Droit\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"TEF_LABEL\"] == \"Sport\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_path, \"working_data_rameau.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(stopwords.words(\"french\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "idx = 1045\n",
    "text = df.loc[idx, 'TITRE']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Éloge de la folie : Adages : Colloques : Réflexions sur l'éducation, la religion, la guerre, la philosophie\" )\n",
    "empty_list = []\n",
    "for token in doc:\n",
    "    empty_list.append(token.lemma_)\n",
    "\n",
    "final_string = ' '.join(map(str,empty_list))\n",
    "print(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Éloge de la folie : Adages : Colloques : Réflexions sur l'éducation, la religion, la guerre, la philosophie\" )\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add words\n",
    "add_words = [\n",
    "        \"la\",\n",
    "        \"de\",\n",
    "        \"le\",\n",
    "        \"les\",\n",
    "        \"l\",\n",
    "        \"au\",\n",
    "        \"du\"\n",
    "]\n",
    "\n",
    "\n",
    "preprocess_text(\n",
    "        text, add_words,\n",
    "        numeric=False, stopw=True,\n",
    "        stem=False, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur un échantillon de notices\n",
    "df_sample = df.sample(n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess titres\n",
    "df_sample['TITRE_processed'] = df_sample['TITRE'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 300\n",
    "print(\"Titre brut: \\n\", df_sample['TITRE'].iloc[idx])\n",
    "print(\"\\nTitre après processing :\\n\", df_sample['TITRE_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['TITRE_processed'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des topics (pyLDAvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'TITRE_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_titres_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des résumés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des résumés\n",
    "df_sample['RESUME_processed'] = df_sample['RESUME'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 12945\n",
    "print(\"Résumé brut: \\n\", df_sample['RESUME'].iloc[idx])\n",
    "print(\"\\nRésumé après processing :\\n\", df_sample['RESUME_processed'].iloc[idx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['RESUME_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'RESUME_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_resumes_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des description (titre+ resumé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des résumés\n",
    "df_sample['DESCR_processed'] = df_sample['DESCR'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 6549\n",
    "print(\"Description brute: \\n\", df_sample['DESCR'].iloc[idx])\n",
    "print(\"\\nDescription après processing :\\n\", df_sample['DESCR_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['DESCR_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'DESCR_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_description_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration TEF labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
