{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données textuelles (titres et/ou résumés)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook explore les concepts RAMEA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from utils_text_processing import *\n",
    "from utils_visualization import *\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres graphiques\n",
    "%matplotlib inline\n",
    "rc = {\n",
    "    'font.size': 14,\n",
    "    'font.family': 'Arial',\n",
    "    'axes.labelsize': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'figure.max_open_warning': 30}\n",
    "\n",
    "sns.set(font='Arial', rc=rc)\n",
    "sns.set_style(\n",
    "    \"whitegrid\", {\n",
    "        'axes.edgecolor': 'k',\n",
    "        'axes.linewidth': 1,\n",
    "        'axes.grid': True,\n",
    "        'xtick.major.width': 1,\n",
    "        'ytick.major.width': 1\n",
    "        })\n",
    "sns.set_context(\n",
    "    \"notebook\",\n",
    "    font_scale=1.1,\n",
    "    rc={\"lines.linewidth\": 1.5})\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autorisation pour la visualisation par pyLDAvis\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "path = \".\"\n",
    "os.chdir(path)\n",
    "data_path = path + \"\\\\data\"\n",
    "output_path = path + \"\\\\outputs\"\n",
    "fig_path = path + \"\\\\figs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "working_data_filename = \"working_data_sans_dewey.csv\"\n",
    "analyse_dewey = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(os.path.join(data_path, working_data_filename), index_col=0)\n",
    "print(f\"le Fichier de données contient {df.shape[0]} lignes et  {df.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des titres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List des stopwords\n",
    "list(set(stopwords.words(\"french\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "idx = 698\n",
    "text = df.loc[idx, 'TITRE']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple lemmatization\n",
    "doc = nlp(text)\n",
    "print(\"Sans lemmatization :\", doc)\n",
    "\n",
    "empty_list = []\n",
    "for token in doc:\n",
    "    empty_list.append(token.lemma_)\n",
    "\n",
    "final_string = ' '.join(map(str,empty_list))\n",
    "print(\"Après lemmatization :\",final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add words\n",
    "add_words = [\n",
    "        \"la\",\n",
    "        \"de\",\n",
    "        \"le\",\n",
    "        \"les\",\n",
    "        \"l\",\n",
    "        \"au\",\n",
    "        \"du\"\n",
    "]\n",
    "\n",
    "\n",
    "preprocess_text(\n",
    "        text, add_words,\n",
    "        numeric=False, stopw=True,\n",
    "        stem=False, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sur un échantillon de notices\n",
    "df_sample = df.sample(n=20000)\n",
    "print(df_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess titres\n",
    "df_sample['TITRE_processed'] = df_sample['TITRE'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 300\n",
    "print(\"Titre brut: \\n\", df_sample['TITRE'].iloc[idx])\n",
    "print(\"\\nTitre après processing :\\n\", df_sample['TITRE_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['TITRE_processed'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des topics (pyLDAvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'TITRE_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_titres_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des résumés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des résumés\n",
    "df_sample['RESUME_processed'] = df_sample['RESUME'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 12945\n",
    "print(\"Résumé brut: \\n\", df_sample['RESUME'].iloc[idx])\n",
    "print(\"\\nRésumé après processing :\\n\", df_sample['RESUME_processed'].iloc[idx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['RESUME_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'RESUME_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_resumes_lemma.html\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des description (titre+ resumé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproces des résumés\n",
    "df_sample['DESCR_processed'] = df_sample['DESCR'].apply(\n",
    "    lambda x: preprocess_text(\n",
    "        x,\n",
    "        add_words=add_words,\n",
    "        numeric=False,\n",
    "        stopw=True,\n",
    "        stem=False,\n",
    "        lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "idx = 6549\n",
    "print(\"Description brute: \\n\", df_sample['DESCR'].iloc[idx])\n",
    "print(\"\\nDescription après processing :\\n\", df_sample['DESCR_processed'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(df_sample['DESCR_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "feature = 'DESCR_processed'\n",
    "model = TfidfVectorizer(\n",
    "    max_features=300,\n",
    "    ngram_range=(1, 5),\n",
    "    min_df=10,\n",
    "    max_df=0.95)\n",
    "cv_transform = model.fit_transform(df_sample[feature])\n",
    "print(\"Dimensions de la matrice\", cv_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction dimension\n",
    "n_comp = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_comp,\n",
    "    learning_method='online',\n",
    "    random_state=42\n",
    "    )\n",
    "x_red = lda.fit_transform(cv_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyLDAvis.sklearn.prepare(lda, cv_transform, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(p, os.path.join(fig_path, \"pyldavis_description_lemma.html\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
